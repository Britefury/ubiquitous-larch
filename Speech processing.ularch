ccopy_reg
_reconstructor
p0
(clarch.apps.project.project_root
ProjectRoot
p1
c__builtin__
object
p2
Ntp3
Rp4
(dp5
S'startup_page_id'
p6
NsS'python_package_name'
p7
Vap
p8
sS'front_page_id'
p9
NsS'contents'
p10
(lp11
g0
(clarch.apps.project.project_page
ProjectPage
p12
g2
Ntp13
Rp14
(dp15
S'data'
p16
g0
(clarch.apps.notebook.notebook
Notebook
p17
g2
Ntp18
Rp19
(dp20
S'blocks'
p21
(lp22
g0
(clarch.apps.notebook.notebook
NotebookBlockCode
p23
g2
Ntp24
Rp25
(dp26
S'code'
p27
g0
(clarch.apps.source_code
PythonCode
p28
g2
Ntp29
Rp30
(dp31
g27
Vfrom larch.pres.html import Html\u000afrom larch.media import audio\u000afrom larch.live import LiveValue, LiveFunction\u000a\u000a\u000aaudio_data = LiveValue()\u000aaudio_sample_rate = LiveValue()\u000aaudio_num_channels = LiveValue()\u000a\u000adef _on_data(data_file, sample_rate, num_samples, num_channels):\u000a    audio_data.value = data_file.read()\u000a    audio_sample_rate.value = sample_rate\u000a    audio_num_channels.value = num_channels\u000a    \u000a    \u000a\u000acap_button = audio.audio_capture_button(1, 'raw16', _on_data)\u000a\u000a\u000a@LiveFunction\u000adef cap_audio():\u000a    if audio_data.value is not None:\u000a        wav_data = audio.raw16_to_wav(audio_data.value, audio_sample_rate.value, audio_num_channels.value)\u000a        return audio.wav_player_from_data(wav_data)\u000a    else:\u000a        return Html('Sound not yet captured')\u000a\u000a\u000acap_button\u000a
p32
sS'editable'
p33
I01
sbsS'notebook'
p34
g19
sbasbsS'name'
p35
Vsample
p36
sS'id'
p37
I0
sbag0
(g12
g2
Ntp38
Rp39
(dp40
g16
g0
(g17
g2
Ntp41
Rp42
(dp43
g21
(lp44
g0
(clarch.apps.notebook.notebook
NotebookBlockText
p45
g2
Ntp46
Rp47
(dp48
S'text'
p49
V<h1>Speech processing example</h1><p><br></p><p>Imports</p>
p50
sg34
g42
sbag0
(g23
g2
Ntp51
Rp52
(dp53
g27
g0
(g28
g2
Ntp54
Rp55
(dp56
g27
Vfrom ap import sample\u000afrom larch.media import audio\u000a\u000a# Function to make wav player from numpy array\u000adef wav_player_from_np_array(y, sample_rate):\u000a    scaled = y * 0x7fff\u000a    raw16_np = np.array(scaled, dtype='short')\u000a    raw16_buffer = str(np.getbuffer(raw16_np))\u000a    return audio.wav_player_from_data(audio.raw16_to_wav(raw16_buffer, sample_rate, 1))\u000a
p57
sg33
I01
sbsg34
g42
sbag0
(g45
g2
Ntp58
Rp59
(dp60
g49
V<h2>Record some audio</h2><p>Click to record:<br></p>
p61
sg34
g42
sbag0
(g23
g2
Ntp62
Rp63
(dp64
g27
g0
(g28
g2
Ntp65
Rp66
(dp67
g27
Vsample.cap_button
p68
sg33
I01
sbsg34
g42
sbag0
(g45
g2
Ntp69
Rp70
(dp71
g49
V<h2>Check your recording</h2>
p72
sg34
g42
sbag0
(g23
g2
Ntp73
Rp74
(dp75
g27
g0
(g28
g2
Ntp76
Rp77
(dp78
g27
Vsample.cap_audio
p79
sg33
I01
sbsg34
g42
sbag0
(g45
g2
Ntp80
Rp81
(dp82
g49
V<h3>Please click the execute button to update everything from here on down.</h3><p>Sample rate:</p>
p83
sg34
g42
sbag0
(g23
g2
Ntp84
Rp85
(dp86
g27
g0
(g28
g2
Ntp87
Rp88
(dp89
g27
Vsample_rate = float(sample.audio_sample_rate.value)\u000asample_rate
p90
sg33
I01
sbsg34
g42
sbag0
(g45
g2
Ntp91
Rp92
(dp93
g49
V<h2>Convert to numpy array and resample:</h2>
p94
sg34
g42
sbag0
(g23
g2
Ntp95
Rp96
(dp97
g27
g0
(g28
g2
Ntp98
Rp99
(dp100
g27
Vimport numpy as np\u000aimport pylab\u000aimport scipy\u000aimport math\u000aimport sys\u000a\u000a\u000adata = sample.audio_data.value\u000ay=np.frombuffer(data, dtype='short').astype('float') * (1.0/0x7fff)\u000a\u000ascale_factor = int(sample_rate)/11000\u000a\u000ay = scipy.signal.resample(y, len(y)/scale_factor)\u000asample_rate = sample_rate / scale_factor\u000a\u000alen(y)
p101
sg33
I01
sbsg34
g42
sbag0
(g45
g2
Ntp102
Rp103
(dp104
g49
V<h2>Settings:</h2>
p105
sg34
g42
sbag0
(g23
g2
Ntp106
Rp107
(dp108
g27
g0
(g28
g2
Ntp109
Rp110
(dp111
g27
VFRAME_PERIOD = 0.02    # 20 ms frames\u000aFRAME_OFFSET = 0.01		# 10 ms apart\u000aHIGH_FREQ_CUTOFF = 5000	# 4KHz\u000aNUM_MEL_FILTERS = 30\u000a#NOISE_SUPPRESSION = 0.000003\u000aNOISE_SUPPRESSION = 0\u000a
p112
sg33
I01
sbsg34
g42
sbag0
(g45
g2
Ntp113
Rp114
(dp115
g49
V<h2>Plot:</h2>
p116
sg34
g42
sbag0
(g23
g2
Ntp117
Rp118
(dp119
g27
g0
(g28
g2
Ntp120
Rp121
(dp122
g27
V\u000a\u000a\u000adef plot_waveform(y):\u000a    pylab.figure(figsize=(16,6))\u000a    pylab.plot(np.arange(y.size)*1000/sample_rate,y)\u000a    pylab.xlabel('Time (ms)')\u000a    return pylab.show()\u000a\u000a\u000aplot_waveform(y)
p123
sg33
I01
sbsg34
g42
sbag0
(g45
g2
Ntp124
Rp125
(dp126
g49
V<h2>Using hamming window to split into 20ms segments</h2><h3>Generate the window first:</h3>
p127
sg34
g42
sbag0
(g23
g2
Ntp128
Rp129
(dp130
g27
g0
(g28
g2
Ntp131
Rp132
(dp133
g27
Vfrom scipy import signal\u000afrom scipy.fftpack import fft, fftshift, ifft\u000awindow = signal.hanning(51)\u000apylab.figure()\u000apylab.plot(window)\u000apylab.title("Hamming window")\u000apylab.ylabel("Amplitude")\u000apylab.xlabel("Sample")\u000apylab.show()\u000a
p134
sg33
I01
sbsg34
g42
sbag0
(g45
g2
Ntp135
Rp136
(dp137
g49
V<p>Apply the hamming window:</p>
p138
sg34
g42
sbag0
(g23
g2
Ntp139
Rp140
(dp141
g27
g0
(g28
g2
Ntp142
Rp143
(dp144
g27
Vdef apply_window(x, N, step):\u000a    window = signal.hanning(N)\u000a    \u000a    res = []\u000a    for i in xrange(0,x.size-N,step):\u000a        res.append(x[i:i+N])\u000a    return res\u000a\u000adef period_to_window_size(time):\u000a    return int(sample_rate * time)\u000a\u000a\u000a\u000aframe_freq = 1.0 / FRAME_PERIOD\u000aframe_time_offset = FRAME_PERIOD * 0.5\u000aframe_samples = period_to_window_size(FRAME_PERIOD)\u000aframe_off_samples = period_to_window_size(FRAME_OFFSET)\u000a\u000a  \u000a\u000ablocks = apply_window(y,frame_samples,frame_off_samples)\u000a\u000aframe_samples, len(blocks)
p145
sg33
I01
sbsg34
g42
sbag0
(g45
g2
Ntp146
Rp147
(dp148
g49
V<p>Invert the hamming procedure:</p>
p149
sg34
g42
sbag0
(g23
g2
Ntp150
Rp151
(dp152
g27
g0
(g28
g2
Ntp153
Rp154
(dp155
g27
Vdef join_frames(frames, frame_offset, frame_size):\u000a    size = frame_size + frame_offset * (len(blocks)-1)\u000a    a = np.zeros(size)\u000a    off = 0\u000a    for frame in frames:\u000a        z = np.zeros(size)\u000a        z[off:off+frame_size] = frame\u000a        a = a + z\u000a        off += frame_offset\u000a    return a\u000a\u000adef wav_player_from_frames(frames, frame_offset, frame_size, sample_rate):\u000a    return wav_player_from_np_array(join_frames(frames, frame_offset, frame_size), sample_rate)\u000a\u000awav_player_from_frames(blocks, frame_off_samples, frame_samples, sample_rate)\u000a
p156
sg33
I01
sbsg34
g42
sbag0
(g45
g2
Ntp157
Rp158
(dp159
g49
V<h2>Use FFT to convert to frequency domain</h2><p>The windowing function removes all frequences below 50hz.</p><p>Discard everything above 5khz</p>
p160
sg34
g42
sbag0
(g23
g2
Ntp161
Rp162
(dp163
g27
g0
(g28
g2
Ntp164
Rp165
(dp166
g27
V# Convert to frequency domain. Save the phase information to allow reconstruction of the original audio.\u000acomplex_spectra = [fft(b)   for b in blocks]\u000athetas = [np.angle(c)   for c in complex_spectra]\u000a# Discard the DC component\u000acomplex_spectra = [c[1:]   for c in complex_spectra]\u000a\u000a# Get an array of frequencies that are represented\u000afrequencies = np.arange(1,complex_spectra[0].size+1) * frame_freq\u000a\u000a# Choose frequences less that the cut-off\u000aselection = [i   for i, f in enumerate(frequencies)   if f <= HIGH_FREQ_CUTOFF]\u000a\u000as_complex_spectra = [f[selection]   for f in complex_spectra]\u000as_frequencies = frequencies[selection]\u000a\u000a# Get power spectra\u000apower_spectra = [abs(c)**2   for c in s_complex_spectra]\u000a\u000a# Suppress noise\u000apeak = max([p.max()   for p in power_spectra])\u000anoise_threshold = peak * NOISE_SUPPRESSION\u000a\u000afor p in power_spectra:\u000a    low_value_flags = p < noise_threshold\u000a    p[low_value_flags] = 0.0\u000a    \u000a    \u000a# Randomise thetas\u000a#thetas = [np.random.random(len(t))*math.pi   for t in thetas]\u000a\u000alen(s_frequencies)
p167
sg33
I01
sbsg34
g42
sbag0
(g45
g2
Ntp168
Rp169
(dp170
g49
V<p>Convert back to spatial and play:</p>
p171
sg34
g42
sbag0
(g23
g2
Ntp172
Rp173
(dp174
g27
g0
(g28
g2
Ntp175
Rp176
(dp177
g27
Vdef wav_from_power_spectra(power_spectra, frame_offset, frame_size, sample_rate):\u000a    abs_spectra = [np.sqrt(p)   for p in power_spectra]\u000a    abs_spectra = [np.append(np.zeros(1), s)   for s in abs_spectra]\u000a    abs_spectra = [np.append(p, np.zeros(frame_samples - len(p)))   for p in abs_spectra]\u000a    #spectra = abs_spectra\u000a    spectra = [a * (np.cos(t) + np.sin(t)*1j)   for a, t in zip(abs_spectra, thetas)]\u000a    spatial = [ifft(f)   for f in spectra]\u000a\u000a    return wav_player_from_frames(spatial, frame_offset, frame_size, sample_rate)\u000a\u000awav_from_power_spectra(power_spectra, frame_off_samples, frame_samples, sample_rate)
p178
sg33
I01
sbsg34
g42
sbag0
(g45
g2
Ntp179
Rp180
(dp181
g49
V<p>Plot frequency data:</p>
p182
sg34
g42
sbag0
(g23
g2
Ntp183
Rp184
(dp185
g27
g0
(g28
g2
Ntp186
Rp187
(dp188
g27
V# Display the log power spectra\u000alog_power_spectra = np.log(np.array(power_spectra)+0.01)\u000a\u000apylab.figure(figsize=(16,6))\u000apylab.imshow(log_power_spectra.transpose(), origin='lower', cmap='binary',aspect=1, interpolation='bicubic')\u000apylab.show()
p189
sg33
I01
sbsg34
g42
sbag0
(g45
g2
Ntp190
Rp191
(dp192
g49
V<h2>Apply Mel filter bank</h2><p>Generate the filters:</p>
p193
sg34
g42
sbag0
(g23
g2
Ntp194
Rp195
(dp196
g27
g0
(g28
g2
Ntp197
Rp198
(dp199
g27
Vfrom scipy.fftpack import dct\u000aimport scipy\u000aimport math\u000a\u000a\u000adef melFilterBank(numFilters, frequencies):\u000a    minHz = min(frequencies)\u000a    maxHz = max(frequencies)\u000a    minMel = freqToMel(minHz)\u000a    maxMel = freqToMel(maxHz)\u000a    \u000a    numPoints = numFilters + 2\u000a        \u000a    points = melToFreq(np.linspace(minMel, maxMel, numPoints))\u000a    \u000a    filterMatrix = np.zeros((numFilters, frequencies.size))\u000a    \u000a    for i in xrange(numFilters):\u000a        start = points[i]\u000a        centre = points[i+1]\u000a        end = points[i+2]\u000a        \u000a        f = scipy.interpolate.interp1d([minHz-1, start,centre,end, maxHz+1], [0.0, 0.0,1.0,0.0, 0.0])\u000a        coeffs = f(frequencies)\u000a        filterMatrix[i] = coeffs\u000a        \u000a        \u000a    return filterMatrix.transpose()\u000a        \u000a    \u000a    \u000a    \u000adef freqToMel(freq):\u000a    return 1127.01048 * np.log(1 + freq / 700.0)\u000a\u000adef melToFreq(mel):\u000a    return 700 * (np.exp(mel / 1127.01048) - 1)\u000a\u000afilters = melFilterBank(NUM_MEL_FILTERS,s_frequencies)\u000apylab.figure()\u000apylab.plot(filters)\u000a#pylab.imshow(filters)\u000apylab.show()\u000a\u000a\u000a\u000a
p200
sg33
I01
sbsg34
g42
sbag0
(g45
g2
Ntp201
Rp202
(dp203
g49
V<p>Apply filters:</p>
p204
sg34
g42
sbag0
(g23
g2
Ntp205
Rp206
(dp207
g27
g0
(g28
g2
Ntp208
Rp209
(dp210
g27
Vdef apply_mel_filter(pwr_spectra):\u000a    return [np.dot(p, filters)   for p in pwr_spectra]\u000a\u000adef inverse_mel_filter(filtered):\u000a    return [np.dot(filters, f)   for f in filtered]\u000a\u000a\u000apylab.figure(figsize=(12,8))\u000amel_filtered = np.array(apply_mel_filter(power_spectra)).transpose()\u000a#pylab.plot(features)\u000apylab.imshow(mel_filtered, origin='lower', aspect=4, interpolation='none')\u000apylab.show()\u000a
p211
sg33
I01
sbsg34
g42
sbag0
(g23
g2
Ntp212
Rp213
(dp214
g27
g0
(g28
g2
Ntp215
Rp216
(dp217
g27
Vwav_from_power_spectra(inverse_mel_filter(apply_mel_filter(power_spectra)), frame_off_samples, frame_samples, sample_rate)
p218
sg33
I01
sbsg34
g42
sbag0
(g45
g2
Ntp219
Rp220
(dp221
g49
V<p>Apply MFCC:</p>
p222
sg34
g42
sbag0
(g23
g2
Ntp223
Rp224
(dp225
g27
g0
(g28
g2
Ntp226
Rp227
(dp228
g27
Vdef mfcc(pwr_spectrum):\u000a    filteredSpec = pwr_spectrum\u000a    filteredSpec = np.dot(pwr_spectrum, filters)\u000a    logSpec = np.log(filteredSpec+1)\u000a    res = dct(logSpec, type=2)\u000a    return res\u000a\u000a\u000adef inv_mfcc(m):\u000a    logSpec = dct(m, type=3)\u000a    filteredSpec = np.exp(logSpec) - 1\u000a    return np.dot(filters, filteredSpec)\u000a\u000a\u000adef wav_from_mfcc(m, frame_off_samples, frame_samples, sample_rate):\u000a    pow_spec = [inv_mfcc(x)   for x in m]\u000a    return wav_from_power_spectra(pow_spec, frame_off_samples, frame_samples, sample_rate)\u000a\u000a\u000a\u000am = [mfcc(p)   for p in power_spectra]\u000a\u000a\u000a\u000af = np.array(m, dtype=float)\u000a#f=f.transpose()\u000apylab.figure(figsize=(12,8))\u000afeatures = f.transpose()[:][1:12]\u000a#pylab.plot(features)\u000apylab.imshow(features, origin='lower', aspect=10, interpolation='none')\u000apylab.show()\u000a
p229
sg33
I01
sbsg34
g42
sbag0
(g23
g2
Ntp230
Rp231
(dp232
g27
g0
(g28
g2
Ntp233
Rp234
(dp235
g27
Vwav_from_mfcc(m, frame_off_samples, frame_samples, sample_rate)
p236
sg33
I01
sbsg34
g42
sbasbsg35
Vprocessing
p237
sg37
I1
sbasb.
ccopy_reg
_reconstructor
p0
(clarch.apps.project.project_root
ProjectRoot
p1
c__builtin__
object
p2
Ntp3
Rp4
(dp5
S'startup_page_id'
p6
NsS'python_package_name'
p7
Vap
p8
sS'front_page_id'
p9
NsS'contents'
p10
(lp11
g0
(clarch.apps.project.project_page
ProjectPage
p12
g2
Ntp13
Rp14
(dp15
S'data'
p16
g0
(clarch.apps.notebook.notebook
Notebook
p17
g2
Ntp18
Rp19
(dp20
S'blocks'
p21
(lp22
g0
(clarch.apps.notebook.notebook
NotebookBlockCode
p23
g2
Ntp24
Rp25
(dp26
S'code'
p27
g0
(clarch.apps.source_code
PythonCode
p28
g2
Ntp29
Rp30
(dp31
g27
Vfrom larch.pres.html import Html\u000afrom larch.media import audio\u000afrom larch.live import LiveValue, LiveFunction\u000a\u000a\u000aaudio_data = LiveValue()\u000aaudio_sample_rate = LiveValue()\u000aaudio_num_channels = LiveValue()\u000a\u000adef _on_data(data_file, sample_rate, num_samples, num_channels):\u000a    audio_data.value = data_file.read()\u000a    audio_sample_rate.value = sample_rate\u000a    audio_num_channels.value = num_channels\u000a    \u000a    \u000a\u000acap_button = audio.audio_capture_button(1, 'raw16', _on_data)\u000a\u000a\u000a@LiveFunction\u000adef cap_audio():\u000a    if audio_data.value is not None:\u000a        wav_data = audio.raw16_to_wav(audio_data.value, audio_sample_rate.value, audio_num_channels.value)\u000a        return audio.wav_player_from_data(wav_data)\u000a    else:\u000a        return Html('Sound not yet captured')\u000a\u000a\u000acap_button\u000a
p32
sS'editable'
p33
I01
sbsS'notebook'
p34
g19
sbasbsS'name'
p35
Vsample
p36
sS'id'
p37
I0
sbag0
(g12
g2
Ntp38
Rp39
(dp40
g16
g0
(g17
g2
Ntp41
Rp42
(dp43
g21
(lp44
g0
(clarch.apps.notebook.notebook
NotebookBlockText
p45
g2
Ntp46
Rp47
(dp48
S'text'
p49
V<h1>Speech processing example</h1><p><br></p><p>Imports</p>
p50
sg34
g42
sbag0
(g23
g2
Ntp51
Rp52
(dp53
g27
g0
(g28
g2
Ntp54
Rp55
(dp56
g27
Vfrom ap import sample
p57
sg33
I01
sbsg34
g42
sbag0
(g45
g2
Ntp58
Rp59
(dp60
g49
V<h2>Record some audio</h2><p>Click to record:<br></p>
p61
sg34
g42
sbag0
(g23
g2
Ntp62
Rp63
(dp64
g27
g0
(g28
g2
Ntp65
Rp66
(dp67
g27
Vsample.cap_button
p68
sg33
I01
sbsg34
g42
sbag0
(g45
g2
Ntp69
Rp70
(dp71
g49
V<h2>Check your recording</h2>
p72
sg34
g42
sbag0
(g23
g2
Ntp73
Rp74
(dp75
g27
g0
(g28
g2
Ntp76
Rp77
(dp78
g27
Vsample.cap_audio
p79
sg33
I01
sbsg34
g42
sbag0
(g45
g2
Ntp80
Rp81
(dp82
g49
V<h3>Please click the execute button to update everything from here on down.</h3><p>Sample rate:</p>
p83
sg34
g42
sbag0
(g23
g2
Ntp84
Rp85
(dp86
g27
g0
(g28
g2
Ntp87
Rp88
(dp89
g27
Vsample_rate = float(sample.audio_sample_rate.value)\u000asample_rate
p90
sg33
I01
sbsg34
g42
sbag0
(g45
g2
Ntp91
Rp92
(dp93
g49
V<h2>Settings:</h2>
p94
sg34
g42
sbag0
(g23
g2
Ntp95
Rp96
(dp97
g27
g0
(g28
g2
Ntp98
Rp99
(dp100
g27
VFRAME_PERIOD = 0.1    # 100 ms frames\u000aFRAME_OFFSET = 0.02		# 20 ms apart\u000aHIGH_FREQ_CUTOFF = 4000	# 5KHz\u000aNUM_MEL_FILTERS = 20\u000aNOISE_SUPPRESSION = 0.000003\u000a
p101
sg33
I01
sbsg34
g42
sbag0
(g45
g2
Ntp102
Rp103
(dp104
g49
V<h2>Convert to numpy array and plot:</h2>
p105
sg34
g42
sbag0
(g23
g2
Ntp106
Rp107
(dp108
g27
g0
(g28
g2
Ntp109
Rp110
(dp111
g27
Vimport numpy as np\u000aimport pylab\u000a\u000adata = sample.audio_data.value\u000ay=np.frombuffer(data, dtype='short') * 1.0/0x7fff\u000a\u000a\u000adef plot_waveform(y):\u000a    pylab.figure()\u000a    pylab.plot(np.arange(y.size)*1000/sample_rate,y)\u000a    pylab.xlabel('Time (ms)')\u000a    return pylab.show()\u000a\u000a\u000aplot_waveform(y)
p112
sg33
I01
sbsg34
g42
sbag0
(g45
g2
Ntp113
Rp114
(dp115
g49
V<h2>Using hamming window to split into 20ms segments</h2><h3>Generate the window first:</h3>
p116
sg34
g42
sbag0
(g23
g2
Ntp117
Rp118
(dp119
g27
g0
(g28
g2
Ntp120
Rp121
(dp122
g27
Vfrom scipy import signal\u000afrom scipy.fftpack import fft, fftshift\u000awindow = signal.hamming(51)\u000apylab.figure()\u000apylab.plot(window)\u000apylab.title("Hamming window")\u000apylab.ylabel("Amplitude")\u000apylab.xlabel("Sample")\u000apylab.show()\u000a
p123
sg33
I01
sbsg34
g42
sbag0
(g45
g2
Ntp124
Rp125
(dp126
g49
V<p>Apply the hamming window:</p>
p127
sg34
g42
sbag0
(g23
g2
Ntp128
Rp129
(dp130
g27
g0
(g28
g2
Ntp131
Rp132
(dp133
g27
Vdef apply_window(x, N, step):\u000a    window = signal.hamming(N)\u000a    \u000a    res = []\u000a    for i in xrange(0,x.size-N,step):\u000a        res.append(x[i:i+N])\u000a    return res\u000a\u000adef period_to_window_size(time):\u000a    return int(sample.audio_sample_rate.value * time)\u000a\u000a\u000a\u000aframe_freq = 1.0 / FRAME_PERIOD\u000aframe_time_offset = FRAME_PERIOD * 0.5\u000aframe_samples = period_to_window_size(FRAME_PERIOD)\u000aframe_off_samples = period_to_window_size(FRAME_OFFSET)\u000a\u000a  \u000a\u000ablocks = apply_window(y,frame_samples,frame_off_samples)\u000a\u000aframe_samples, len(blocks)
p134
sg33
I01
sbsg34
g42
sbag0
(g45
g2
Ntp135
Rp136
(dp137
g49
V<h2>Use FFT to convert to frequency domain</h2><p>The windowing function removes all frequences below 50hz.</p><p>Discard everything above 5khz</p>
p138
sg34
g42
sbag0
(g23
g2
Ntp139
Rp140
(dp141
g27
g0
(g28
g2
Ntp142
Rp143
(dp144
g27
Vcomplex_spectra = [fft(b)[1:]   for b in blocks]\u000a\u000afrequencies = np.arange(1,complex_spectra[0].size+1) * frame_freq\u000a\u000aselection = [i   for i, f in enumerate(frequencies)   if f <= HIGH_FREQ_CUTOFF]\u000a\u000as_complex_spectra = [f[selection]   for f in complex_spectra]\u000as_frequencies = frequencies[selection]\u000a\u000apower_spectra = [abs(c)**2   for c in s_complex_spectra]\u000a\u000apeak = max([p.max()   for p in power_spectra])\u000anoise_threshold = peak * NOISE_SUPPRESSION\u000a\u000apower_spectra = [p.clip(noise_threshold,peak)   for p in power_spectra]\u000a\u000alen(s_frequencies)
p145
sg33
I01
sbsg34
g42
sbag0
(g45
g2
Ntp146
Rp147
(dp148
g49
V<p>Plot frequency data:</p>
p149
sg34
g42
sbag0
(g23
g2
Ntp150
Rp151
(dp152
g27
g0
(g28
g2
Ntp153
Rp154
(dp155
g27
Vpylab.figure(figsize=(6,8))\u000apylab.imshow(np.log(np.array(power_spectra)).transpose(), origin='lower', cmap='gray',aspect=1, interpolation='none')\u000apylab.show()
p156
sg33
I01
sbsg34
g42
sbag0
(g45
g2
Ntp157
Rp158
(dp159
g49
V<h2>Apply Mel filter bank</h2><p>Generate the filters:</p>
p160
sg34
g42
sbag0
(g23
g2
Ntp161
Rp162
(dp163
g27
g0
(g28
g2
Ntp164
Rp165
(dp166
g27
Vfrom scipy.fftpack import dct\u000aimport scipy\u000aimport math\u000a\u000a\u000adef melFilterBank(numFilters, frequencies):\u000a    minHz = min(frequencies)\u000a    maxHz = max(frequencies)\u000a    minMel = freqToMel(minHz)\u000a    maxMel = freqToMel(maxHz)\u000a    \u000a    numPoints = numFilters + 2\u000a        \u000a    points = melToFreq(np.linspace(minMel, maxMel, numPoints))\u000a    \u000a    filterMatrix = np.zeros((numFilters, frequencies.size))\u000a    \u000a    for i in xrange(numFilters):\u000a        start = points[i]\u000a        centre = points[i+1]\u000a        end = points[i+2]\u000a        \u000a        f = scipy.interpolate.interp1d([minHz-1, start,centre,end, maxHz+1], [0.0, 0.0,1.0,0.0, 0.0])\u000a        coeffs = f(frequencies)\u000a        filterMatrix[i] = coeffs\u000a        \u000a        \u000a    return filterMatrix.transpose()\u000a        \u000a    \u000a    \u000a    \u000adef freqToMel(freq):\u000a    return 1127.01048 * np.log(1 + freq / 700.0)\u000a\u000adef melToFreq(mel):\u000a    return 700 * (np.exp(mel / 1127.01048) - 1)\u000a\u000afilters = melFilterBank(NUM_MEL_FILTERS,s_frequencies)\u000apylab.figure()\u000apylab.plot(filters)\u000a#pylab.imshow(filters)\u000apylab.show()\u000a\u000a\u000a\u000a
p167
sg33
I01
sbsg34
g42
sbag0
(g45
g2
Ntp168
Rp169
(dp170
g49
V<p>Apply filters:</p>
p171
sg34
g42
sbag0
(g23
g2
Ntp172
Rp173
(dp174
g27
g0
(g28
g2
Ntp175
Rp176
(dp177
g27
Vdef mfcc(pwr_spectrum, freqs):\u000a    filteredSpec = pwr_spectrum\u000a    filteredSpec = np.dot(pwr_spectrum, filters)\u000a    logSpec = np.log(filteredSpec)\u000a    res = dct(logSpec, type=2)\u000a    return res\u000a\u000a\u000a\u000am = [mfcc(p, s_frequencies)   for p in power_spectra]\u000a\u000a\u000a\u000a\u000af = np.array(m, dtype=float)\u000a#f=f.transpose()\u000apylab.figure(figsize=(12,8))\u000afeatures = f.transpose()[:][1:10]\u000a#pylab.plot(features)\u000apylab.imshow(features, origin='lower', aspect=5, interpolation='none')\u000apylab.show()\u000a
p178
sg33
I01
sbsg34
g42
sbasbsg35
Vprocessing
p179
sg37
I1
sbasb.
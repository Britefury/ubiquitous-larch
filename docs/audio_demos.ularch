ccopy_reg
_reconstructor
p0
(clarch.apps.project.project_root
ProjectRoot
p1
c__builtin__
object
p2
Ntp3
Rp4
(dp5
S'startup_page_id'
p6
NsS'python_package_name'
p7
Vdocs_audio_demos
p8
sS'front_page_id'
p9
NsS'contents'
p10
(lp11
g0
(clarch.apps.project.project_page
ProjectPage
p12
g2
Ntp13
Rp14
(dp15
S'data'
p16
g0
(clarch.apps.notebook.notebook
Notebook
p17
g2
Ntp18
Rp19
(dp20
S'blocks'
p21
(lp22
g0
(clarch.apps.notebook.notebook
NotebookBlockCode
p23
g2
Ntp24
Rp25
(dp26
S'code'
p27
g0
(clarch.apps.source_code
PythonCode
p28
g2
Ntp29
Rp30
(dp31
g27
Vfrom larch.pres.html import Html\u000afrom larch.media import audio\u000afrom larch.live import LiveValue, LiveFunction\u000a\u000a\u000aaudio_data = LiveValue()\u000aaudio_sample_rate = LiveValue()\u000aaudio_num_channels = LiveValue()\u000a\u000adef _on_data(data_file, sample_rate, num_samples, num_channels):\u000a    audio_data.value = data_file.read()\u000a    audio_sample_rate.value = sample_rate\u000a    audio_num_channels.value = num_channels\u000a    \u000a    \u000a\u000acap_button = audio.audio_capture_button(1, 'raw16', _on_data)\u000a\u000a\u000a@LiveFunction\u000adef cap_audio():\u000a    if audio_data.value is not None:\u000a        wav_data = audio.raw16_to_wav(audio_data.value, audio_sample_rate.value, audio_num_channels.value)\u000a        return audio.wav_player_from_data(wav_data)\u000a    else:\u000a        return Html('Sound not yet captured')\u000a\u000a\u000acap_button\u000a
p32
sS'editable'
p33
I01
sbsS'notebook'
p34
g19
sbasbsS'name'
p35
Vsample
p36
sS'id'
p37
I0
sbag0
(g12
g2
Ntp38
Rp39
(dp40
g16
g0
(g17
g2
Ntp41
Rp42
(dp43
g21
(lp44
g0
(clarch.apps.notebook.notebook
NotebookBlockText
p45
g2
Ntp46
Rp47
(dp48
S'text'
p49
V<h1>Speech processing example</h1><p><br></p><p>Functions from the&nbsp;<a data-cke-saved-href="/pages/docs/audio_demos/audio_processing" href="http://127.0.0.1:5000/pages/docs/audio_demos/audio_processing">audio_processing module</a>&nbsp;are used to simplify this notebook.<br></p><p>Imports</p>
p50
sg34
g42
sbag0
(g23
g2
Ntp51
Rp52
(dp53
g27
g0
(g28
g2
Ntp54
Rp55
(dp56
g27
Vfrom docs_audio_demos import sample, audio_processing\u000afrom larch.media import audio\u000a\u000a
p57
sg33
I01
sbsg34
g42
sbag0
(g45
g2
Ntp58
Rp59
(dp60
g49
V<h2>Record some audio</h2><p>Click to record:</p>
p61
sg34
g42
sbag0
(g23
g2
Ntp62
Rp63
(dp64
g27
g0
(g28
g2
Ntp65
Rp66
(dp67
g27
Vsample.cap_button
p68
sg33
I01
sbsg34
g42
sbag0
(g45
g2
Ntp69
Rp70
(dp71
g49
V<h2>Check your recording</h2>
p72
sg34
g42
sbag0
(g23
g2
Ntp73
Rp74
(dp75
g27
g0
(g28
g2
Ntp76
Rp77
(dp78
g27
Vsample.cap_audio
p79
sg33
I01
sbsg34
g42
sbag0
(g45
g2
Ntp80
Rp81
(dp82
g49
V<h3>Please click the execute button to update everything from here on down.</h3><p>Sample rate:</p>
p83
sg34
g42
sbag0
(g23
g2
Ntp84
Rp85
(dp86
g27
g0
(g28
g2
Ntp87
Rp88
(dp89
g27
Vsample_rate = float(sample.audio_sample_rate.value)\u000asample_rate
p90
sg33
I01
sbsg34
g42
sbag0
(g45
g2
Ntp91
Rp92
(dp93
g49
V<h2>Convert to numpy array and resample:</h2>
p94
sg34
g42
sbag0
(g23
g2
Ntp95
Rp96
(dp97
g27
g0
(g28
g2
Ntp98
Rp99
(dp100
g27
Vimport numpy as np\u000aimport pylab\u000aimport scipy\u000aimport math\u000aimport sys\u000a\u000a\u000adata = sample.audio_data.value\u000ay=np.frombuffer(data, dtype='short').astype('float') * (1.0/0x7fff)\u000a\u000ascale_factor = int(sample_rate)/11000\u000a\u000ay = scipy.signal.resample(y, len(y)/scale_factor)\u000asample_rate = sample_rate / scale_factor\u000a\u000alen(y)
p101
sg33
I01
sbsg34
g42
sbag0
(g45
g2
Ntp102
Rp103
(dp104
g49
V<h2>Settings:</h2>
p105
sg34
g42
sbag0
(g23
g2
Ntp106
Rp107
(dp108
g27
g0
(g28
g2
Ntp109
Rp110
(dp111
g27
VFRAME_PERIOD = 0.02    # 20 ms frames\u000aHIGH_FREQ_CUTOFF = 5000	# 4KHz\u000aNUM_MEL_FILTERS = 30\u000a#NOISE_SUPPRESSION = 0.000003\u000aNOISE_SUPPRESSION = 0\u000a
p112
sg33
I01
sbsg34
g42
sbag0
(g45
g2
Ntp113
Rp114
(dp115
g49
V<h2>Plot:</h2>
p116
sg34
g42
sbag0
(g23
g2
Ntp117
Rp118
(dp119
g27
g0
(g28
g2
Ntp120
Rp121
(dp122
g27
Vaudio_processing.plot_waveform(y, 44100)
p123
sg33
I01
sbsg34
g42
sbag0
(g45
g2
Ntp124
Rp125
(dp126
g49
V<h2>Using hanning window to split into frames</h2>
p127
sg34
g42
sbag0
(g23
g2
Ntp128
Rp129
(dp130
g27
g0
(g28
g2
Ntp131
Rp132
(dp133
g27
V\u000a  \u000a\u000ablocks = audio_processing.apply_hanning_window(y, sample_rate, FRAME_PERIOD)\u000a\u000alen(blocks), len(blocks[0])
p134
sg33
I01
sbsg34
g42
sbag0
(g45
g2
Ntp135
Rp136
(dp137
g49
V<p>Invert the hanning window to recover the waveform:</p>
p138
sg34
g42
sbag0
(g23
g2
Ntp139
Rp140
(dp141
g27
g0
(g28
g2
Ntp142
Rp143
(dp144
g27
Vaudio_processing.wav_player_from_windowed_frames(blocks, sample_rate)\u000a
p145
sg33
I01
sbsg34
g42
sbag0
(g45
g2
Ntp146
Rp147
(dp148
g49
V<h2>Use FFT to convert to frequency domain</h2><p>The windowing function removes all frequences below 50hz.</p><p>Discard everything above 5khz</p>
p149
sg34
g42
sbag0
(g23
g2
Ntp150
Rp151
(dp152
g27
g0
(g28
g2
Ntp153
Rp154
(dp155
g27
Vfrom numpy import fft\u000a\u000a# Convert to frequency domain. \u000acomplex_spectra = audio_processing.spatial_to_freq(blocks)\u000a\u000a# Save the phase information to allow reconstruction of the original audio.\u000athetas = audio_processing.freq_to_phase(complex_spectra)\u000a# Discard the DC component\u000acomplex_spectra = audio_processing.discard_dc_component(complex_spectra)\u000a\u000a# Get an array of frequencies that are represented\u000afrequencies = np.arange(1,complex_spectra[0].size+1) * (1.0 / FRAME_PERIOD)\u000a\u000a# Choose frequences less that the cut-off\u000aselection = [i   for i, f in enumerate(frequencies)   if f <= HIGH_FREQ_CUTOFF]\u000a\u000as_complex_spectra = [f[selection]   for f in complex_spectra]\u000as_frequencies = frequencies[selection]\u000a\u000a# Get power spectra\u000apower_spectra = [abs(c)**2   for c in s_complex_spectra]\u000a\u000a# Suppress noise\u000apeak = max([p.max()   for p in power_spectra])\u000anoise_threshold = peak * NOISE_SUPPRESSION\u000a\u000afor p in power_spectra:\u000a    low_value_flags = p < noise_threshold\u000a    p[low_value_flags] = 0.0\u000a    \u000a    \u000a# Randomise thetas\u000a#thetas = [np.random.random(len(t))*math.pi   for t in thetas]\u000a\u000alen(s_frequencies)
p156
sg33
I01
sbsg34
g42
sbag0
(g45
g2
Ntp157
Rp158
(dp159
g49
V<p>Convert back to spatial and play:</p>
p160
sg34
g42
sbag0
(g23
g2
Ntp161
Rp162
(dp163
g27
g0
(g28
g2
Ntp164
Rp165
(dp166
g27
Vdef wav_from_power_spectra(power_spectra, block_size, sample_rate):\u000a    abs_spectra = [np.sqrt(p)   for p in power_spectra]\u000a    abs_spectra = [np.append(np.zeros(1), s)   for s in abs_spectra]\u000a    abs_spectra = [np.append(p, np.zeros(block_size - len(p)))   for p in abs_spectra]\u000a    #spectra = abs_spectra\u000a    spectra = [a * (np.cos(t) + np.sin(t)*1j)   for a, t in zip(abs_spectra, thetas)]\u000a    spatial = [fft.ifft(f)   for f in spectra]\u000a\u000a    return audio_processing.wav_player_from_windowed_frames(spatial, sample_rate)\u000a\u000awav_from_power_spectra(power_spectra, len(blocks[0]), sample_rate)
p167
sg33
I01
sbsg34
g42
sbag0
(g45
g2
Ntp168
Rp169
(dp170
g49
V<p>Plot frequency data:</p>
p171
sg34
g42
sbag0
(g23
g2
Ntp172
Rp173
(dp174
g27
g0
(g28
g2
Ntp175
Rp176
(dp177
g27
V# Display the log power spectra\u000alog_power_spectra = np.log(np.array(power_spectra)+0.01)\u000a\u000apylab.figure(figsize=(16,6))\u000apylab.imshow(log_power_spectra.transpose(), origin='lower', cmap='binary',aspect=1, interpolation='bicubic')\u000apylab.show()
p178
sg33
I01
sbsg34
g42
sbag0
(g45
g2
Ntp179
Rp180
(dp181
g49
V<h2>Apply Mel filter bank</h2><p>Generate the filters:</p>
p182
sg34
g42
sbag0
(g23
g2
Ntp183
Rp184
(dp185
g27
g0
(g28
g2
Ntp186
Rp187
(dp188
g27
Vfrom scipy.fftpack import dct\u000aimport scipy\u000aimport math\u000a\u000a\u000adef melFilterBank(numFilters, frequencies):\u000a    minHz = min(frequencies)\u000a    maxHz = max(frequencies)\u000a    minMel = freqToMel(minHz)\u000a    maxMel = freqToMel(maxHz)\u000a    \u000a    numPoints = numFilters + 2\u000a        \u000a    points = melToFreq(np.linspace(minMel, maxMel, numPoints))\u000a    \u000a    filterMatrix = np.zeros((numFilters, frequencies.size))\u000a    \u000a    for i in xrange(numFilters):\u000a        start = points[i]\u000a        centre = points[i+1]\u000a        end = points[i+2]\u000a        \u000a        f = scipy.interpolate.interp1d([minHz-1, start,centre,end, maxHz+1], [0.0, 0.0,1.0,0.0, 0.0])\u000a        coeffs = f(frequencies)\u000a        filterMatrix[i] = coeffs\u000a        \u000a        \u000a    return filterMatrix.transpose()\u000a        \u000a    \u000a    \u000a    \u000adef freqToMel(freq):\u000a    return 1127.01048 * np.log(1 + freq / 700.0)\u000a\u000adef melToFreq(mel):\u000a    return 700 * (np.exp(mel / 1127.01048) - 1)\u000a\u000afilters = melFilterBank(NUM_MEL_FILTERS,s_frequencies)\u000apylab.figure()\u000apylab.plot(filters)\u000a#pylab.imshow(filters)\u000apylab.show()\u000a\u000a\u000a\u000a
p189
sg33
I01
sbsg34
g42
sbag0
(g45
g2
Ntp190
Rp191
(dp192
g49
V<p>Apply filters:</p>
p193
sg34
g42
sbag0
(g23
g2
Ntp194
Rp195
(dp196
g27
g0
(g28
g2
Ntp197
Rp198
(dp199
g27
Vdef apply_mel_filter(pwr_spectra):\u000a    return [np.dot(p, filters)   for p in pwr_spectra]\u000a\u000adef inverse_mel_filter(filtered):\u000a    return [np.dot(filters, f)   for f in filtered]\u000a\u000a\u000apylab.figure(figsize=(12,8))\u000amel_filtered = np.array(apply_mel_filter(power_spectra)).transpose()\u000a#pylab.plot(features)\u000apylab.imshow(mel_filtered, origin='lower', aspect=4, interpolation='none')\u000apylab.show()\u000a
p200
sg33
I01
sbsg34
g42
sbag0
(g23
g2
Ntp201
Rp202
(dp203
g27
g0
(g28
g2
Ntp204
Rp205
(dp206
g27
Vwav_from_power_spectra(inverse_mel_filter(apply_mel_filter(power_spectra)), len(blocks[0]), sample_rate)
p207
sg33
I01
sbsg34
g42
sbag0
(g45
g2
Ntp208
Rp209
(dp210
g49
V<p>Apply MFCC:</p>
p211
sg34
g42
sbag0
(g23
g2
Ntp212
Rp213
(dp214
g27
g0
(g28
g2
Ntp215
Rp216
(dp217
g27
Vdef mfcc(pwr_spectrum):\u000a    filteredSpec = pwr_spectrum\u000a    filteredSpec = np.dot(pwr_spectrum, filters)\u000a    logSpec = np.log(filteredSpec+1)\u000a    res = dct(logSpec, type=2)\u000a    return res\u000a\u000a\u000adef inv_mfcc(m):\u000a    logSpec = dct(m, type=3)\u000a    filteredSpec = np.exp(logSpec) - 1\u000a    return np.dot(filters, filteredSpec)\u000a\u000a\u000adef wav_from_mfcc(m, blocks, sample_rate):\u000a    pow_spec = [inv_mfcc(x)   for x in m]\u000a    return wav_from_power_spectra(pow_spec, len(blocks[0]), sample_rate)\u000a\u000a\u000a\u000am = [mfcc(p)   for p in power_spectra]\u000a\u000a\u000a\u000af = np.array(m, dtype=float)\u000a#f=f.transpose()\u000apylab.figure(figsize=(12,8))\u000afeatures = f.transpose()[:][1:12]\u000a#pylab.plot(features)\u000apylab.imshow(features, origin='lower', aspect=10, interpolation='none')\u000apylab.show()\u000a
p218
sg33
I01
sbsg34
g42
sbag0
(g23
g2
Ntp219
Rp220
(dp221
g27
g0
(g28
g2
Ntp222
Rp223
(dp224
g27
Vwav_from_mfcc(m, blocks, sample_rate)
p225
sg33
I01
sbsg34
g42
sbasbsg35
Vprocessing
p226
sg37
I1
sbag0
(g12
g2
Ntp227
Rp228
(dp229
g16
g0
(g17
g2
Ntp230
Rp231
(dp232
g21
(lp233
g0
(g45
g2
Ntp234
Rp235
(dp236
g49
V<h1 style="text-align: center;">Audio processing functions</h1>
p237
sg34
g231
sbag0
(g45
g2
Ntp238
Rp239
(dp240
g49
V<p>Numpy array to WAV player</p>
p241
sg34
g231
sbag0
(g23
g2
Ntp242
Rp243
(dp244
g27
g0
(g28
g2
Ntp245
Rp246
(dp247
g27
Vfrom larch.media import audio\u000aimport numpy as np\u000a\u000a# Function to make wav player from numpy array\u000adef wav_player_from_np_array(y, sample_rate):\u000a    scaled = y * 0x7fff\u000a    raw16_np = np.array(scaled, dtype='short')\u000a    raw16_buffer = str(np.getbuffer(raw16_np))\u000a    return audio.wav_player_from_data(audio.raw16_to_wav(raw16_buffer, sample_rate, 1))\u000a\u000a# Test:\u000afrom scipy import signal\u000asquare_wave = signal.square(2 * np.pi * 200.0 * np.linspace(0, 0.25, 11025)) * 0.25 # Scale it down; it doesn't sound nice\u000awav_player_from_np_array(square_wave, 44100)
p248
sg33
I01
sbsg34
g231
sbag0
(g45
g2
Ntp249
Rp250
(dp251
g49
V<p>Waveform plot</p>
p252
sg34
g231
sbag0
(g23
g2
Ntp253
Rp254
(dp255
g27
g0
(g28
g2
Ntp256
Rp257
(dp258
g27
Vimport pylab\u000a\u000adef plot_waveform(y, sample_rate, figsize=(16,6)):\u000a    pylab.figure(figsize=figsize)\u000a    pylab.plot(np.arange(y.size)*1000/sample_rate,y)\u000a    pylab.xlabel('Time (ms)')\u000a    return pylab.show()\u000a\u000a\u000aplot_waveform(square_wave, 44100, figsize=(8,6))
p259
sg33
I01
sbsg34
g231
sbag0
(g45
g2
Ntp260
Rp261
(dp262
g49
V<p>Hanning window:</p>
p263
sg34
g231
sbag0
(g23
g2
Ntp264
Rp265
(dp266
g27
g0
(g28
g2
Ntp267
Rp268
(dp269
g27
Vdef _apply_window(x, N, step):\u000a    window = signal.hanning(N)\u000a    \u000a    res = []\u000a    for i in xrange(0,x.size-N,step):\u000a        res.append(x[i:i+N])\u000a    return res\u000a\u000adef _period_to_window_size(time, sample_rate):\u000a    return int(sample_rate * time)\u000a\u000a\u000adef apply_hanning_window(x, sample_rate, frame_period):\u000a    num_samples = len(x)\u000a    frame_freq = 1.0 / frame_period\u000a    frame_time_offset = frame_period * 0.5\u000a    frame_samples = int(frame_period * num_samples)\u000a    frame_off_samples = int(frame_time_offset * num_samples)\u000a    return _apply_window(x, frame_samples, frame_off_samples)\u000a\u000ablocks = apply_hanning_window(square_wave, 44100, 0.02)
p270
sg33
I01
sbsg34
g231
sbag0
(g45
g2
Ntp271
Rp272
(dp273
g49
V<p>Invert windowing by joining frames</p>
p274
sg34
g231
sbag0
(g23
g2
Ntp275
Rp276
(dp277
g27
g0
(g28
g2
Ntp278
Rp279
(dp280
g27
Vdef join_windowed_frames(frames):\u000a    frame_size = len(frames[0])\u000a    frame_offset = frame_size / 2\u000a    \u000a    size = frame_size + frame_offset * (len(blocks)-1)\u000a    a = np.zeros(size)\u000a    off = 0\u000a    for frame in frames:\u000a        z = np.zeros(size)\u000a        z[off:off+frame_size] = frame\u000a        a = a + z\u000a        off += frame_offset\u000a    return a\u000a\u000adef wav_player_from_windowed_frames(frames, sample_rate):\u000a    return wav_player_from_np_array(join_windowed_frames(frames), sample_rate)\u000a\u000awav_player_from_windowed_frames(blocks, 44100)
p281
sg33
I01
sbsg34
g231
sbag0
(g45
g2
Ntp282
Rp283
(dp284
g49
V<p>Convert to frequency domain:</p>
p285
sg34
g231
sbag0
(g23
g2
Ntp286
Rp287
(dp288
g27
g0
(g28
g2
Ntp289
Rp290
(dp291
g27
Vfrom numpy import fft\u000a\u000adef spatial_to_freq(frames):\u000a    return [fft.fft(f)   for f in frames]
p292
sg33
I01
sbsg34
g231
sbag0
(g45
g2
Ntp293
Rp294
(dp295
g49
V<p>WAV from freq domain:</p>
p296
sg34
g231
sbag0
(g23
g2
Ntp297
Rp298
(dp299
g27
g0
(g28
g2
Ntp300
Rp301
(dp302
g27
Vdef wav_player_from_freq_windowed_frames(frames_in_freq_domain, sample_rate):\u000a    spatial = [fft.ifft(f)   for f in frames_in_freq_domain]\u000a    return wav_player_from_windowed_frames(spatial, sample_rate)\u000a\u000awav_player_from_freq_windowed_frames(spatial_to_freq(blocks), 44100)
p303
sg33
I01
sbsg34
g231
sbag0
(g45
g2
Ntp304
Rp305
(dp306
g49
V<p>Phase extraction:</p>
p307
sg34
g231
sbag0
(g23
g2
Ntp308
Rp309
(dp310
g27
g0
(g28
g2
Ntp311
Rp312
(dp313
g27
Vdef freq_to_phase(frames_in_freq_domain):\u000a    return [np.angle(complex_spectrum)   for complex_spectrum in frames_in_freq_domain]
p314
sg33
I01
sbsg34
g231
sbag0
(g45
g2
Ntp315
Rp316
(dp317
g49
V<p>Discard DC:</p>
p318
sg34
g231
sbag0
(g23
g2
Ntp319
Rp320
(dp321
g27
g0
(g28
g2
Ntp322
Rp323
(dp324
g27
Vdef discard_dc_component(frames_in_freq_domain):\u000a    return [c[1:]   for c in frames_in_freq_domain]\u000a
p325
sg33
I01
sbsg34
g231
sbag0
(g45
g2
Ntp326
Rp327
(dp328
g49
V<p>Power spectra:</p>
p329
sg34
g231
sbag0
(g23
g2
Ntp330
Rp331
(dp332
g27
g0
(g28
g2
Ntp333
Rp334
(dp335
g27
Vdef power_spectra(frames_in_freq_domain):\u000a    return [abs(c)**2   for c in frames_in_freq_domain]\u000a
p336
sg33
I01
sbsg34
g231
sbag0
(g45
g2
Ntp337
Rp338
(dp339
g49
V<p>Power spectra plot</p>
p340
sg34
g231
sbag0
(g23
g2
Ntp341
Rp342
(dp343
g27
g0
(g28
g2
Ntp344
Rp345
(dp346
g27
Vdef log_power_spectra_plot(power_spectrum_frames):\u000a    # Display the log power spectra\u000a    log_power_spectra = np.log(np.array(power_spectrum_frames)+0.01)\u000a    \u000a    pylab.figure(figsize=(16,6))\u000a    pylab.imshow(log_power_spectra.transpose(), origin='lower', cmap='binary',aspect=1, interpolation='bicubic')\u000a    return pylab.show()
p347
sg33
I01
sbsg34
g231
sbasbsg35
Vaudio_processing
p348
sg37
I2
sbag0
(g12
g2
Ntp349
Rp350
(dp351
g16
g0
(g17
g2
Ntp352
Rp353
(dp354
g21
(lp355
g0
(g45
g2
Ntp356
Rp357
(dp358
g49
V<h1 style="text-align:center">Voice modulator</h1><p><br></p><p>Scroll to the bottom for an interactive voice frequency modulator.</p><p>Functions from the <a data-cke-saved-href="/pages/docs/audio_demos/audio_processing" href="/pages/docs/audio_demos/audio_processing">audio_processing module</a> are used to simplify this notebook.</p>
p359
sg34
g353
sbag0
(g23
g2
Ntp360
Rp361
(dp362
g27
g0
(g28
g2
Ntp363
Rp364
(dp365
g27
Vfrom docs_audio_demos import sample, audio_processing\u000afrom larch.media import audio\u000a\u000aimport numpy as np\u000aimport pylab\u000aimport scipy\u000aimport math\u000aimport sys\u000a\u000a
p366
sg33
I01
sbsg34
g353
sbag0
(g45
g2
Ntp367
Rp368
(dp369
g49
V<h2>Record some audio</h2><p>Click to record:</p>
p370
sg34
g353
sbag0
(g23
g2
Ntp371
Rp372
(dp373
g27
g0
(g28
g2
Ntp374
Rp375
(dp376
g27
Vsample.cap_button
p377
sg33
I01
sbsg34
g353
sbag0
(g45
g2
Ntp378
Rp379
(dp380
g49
V<h2>Check your recording</h2>
p381
sg34
g353
sbag0
(g23
g2
Ntp382
Rp383
(dp384
g27
g0
(g28
g2
Ntp385
Rp386
(dp387
g27
Vsample.cap_audio
p388
sg33
I01
sbsg34
g353
sbag0
(g45
g2
Ntp389
Rp390
(dp391
g49
V<h3>Please click the execute button to update everything from here on down.</h3><p>Sample rate:</p>
p392
sg34
g353
sbag0
(g23
g2
Ntp393
Rp394
(dp395
g27
g0
(g28
g2
Ntp396
Rp397
(dp398
g27
Vsample_rate = float(sample.audio_sample_rate.value)\u000asample_rate
p399
sg33
I01
sbsg34
g353
sbag0
(g45
g2
Ntp400
Rp401
(dp402
g49
V<h2>Convert to numpy array and resample:</h2>
p403
sg34
g353
sbag0
(g23
g2
Ntp404
Rp405
(dp406
g27
g0
(g28
g2
Ntp407
Rp408
(dp409
g27
Vdata = sample.audio_data.value\u000ay=np.frombuffer(data, dtype='short').astype('float') * (1.0/0x7fff)\u000a\u000ascale_factor = int(sample_rate)/22000\u000a\u000ay = scipy.signal.resample(y, len(y)/scale_factor)\u000asample_rate = sample_rate / scale_factor
p410
sg33
I01
sbsg34
g353
sbag0
(g45
g2
Ntp411
Rp412
(dp413
g49
V<h2>Settings:</h2>
p414
sg34
g353
sbag0
(g23
g2
Ntp415
Rp416
(dp417
g27
g0
(g28
g2
Ntp418
Rp419
(dp420
g27
VFRAME_PERIOD = 0.02    # 20 ms frames
p421
sg33
I01
sbsg34
g353
sbag0
(g45
g2
Ntp422
Rp423
(dp424
g49
V<h2>Plot:</h2>
p425
sg34
g353
sbag0
(g23
g2
Ntp426
Rp427
(dp428
g27
g0
(g28
g2
Ntp429
Rp430
(dp431
g27
Vaudio_processing.plot_waveform(y, 44100, (12,4))
p432
sg33
I01
sbsg34
g353
sbag0
(g45
g2
Ntp433
Rp434
(dp435
g49
V<h2>Using hanning window to split into frames</h2>
p436
sg34
g353
sbag0
(g23
g2
Ntp437
Rp438
(dp439
g27
g0
(g28
g2
Ntp440
Rp441
(dp442
g27
Vframes = audio_processing.apply_hanning_window(y, sample_rate, FRAME_PERIOD)\u000a\u000a# Show number of frames and frame size\u000alen(frames), len(frames[0])
p443
sg33
I01
sbsg34
g353
sbag0
(g45
g2
Ntp444
Rp445
(dp446
g49
V<h2>Use FFT to convert to frequency domain</h2>
p447
sg34
g353
sbag0
(g23
g2
Ntp448
Rp449
(dp450
g27
g0
(g28
g2
Ntp451
Rp452
(dp453
g27
Vfrom numpy import fft\u000a\u000a# Convert to frequency domain. \u000aframes_freq = audio_processing.spatial_to_freq(frames)\u000apwr_spec_frames = audio_processing.power_spectra(frames_freq)\u000a\u000aaudio_processing.log_power_spectra_plot([f[:len(f)/8]   for f in pwr_spec_frames])
p454
sg33
I01
sbsg34
g353
sbag0
(g45
g2
Ntp455
Rp456
(dp457
g49
V<p>Check still plays:</p>
p458
sg34
g353
sbag0
(g23
g2
Ntp459
Rp460
(dp461
g27
g0
(g28
g2
Ntp462
Rp463
(dp464
g27
Vaudio_processing.wav_player_from_freq_windowed_frames(frames_freq, sample_rate)
p465
sg33
I01
sbsg34
g353
sbag0
(g45
g2
Ntp466
Rp467
(dp468
g49
V<p>Filter</p>
p469
sg34
g353
sbag0
(g23
g2
Ntp470
Rp471
(dp472
g27
g0
(g28
g2
Ntp473
Rp474
(dp475
g27
Vfrom scipy.fftpack import dct\u000aimport scipy\u000aimport math\u000a\u000a\u000adef filter_bank(frame_size, gradient):\u000a    minHz = 1.0\u000a    maxHz = frame_size\u000a    \u000a    points = np.linspace(0, frame_size-1, frame_size)\u000a    \u000a    filterMatrix = np.zeros((frame_size, frame_size))\u000a    \u000a    for i in xrange(frame_size):\u000a        start = (i - 1.0) * gradient\u000a        centre = float(i) * gradient\u000a        end = (i + 1.0) * gradient\u000a        \u000a        f = scipy.interpolate.interp1d([min(start, -1000), start,centre,end, max(end,frame_size+1000)],\u000a                                       [0.0, 0.0,1.0,0.0, 0.0])\u000a        coeffs = f(points)\u000a        filterMatrix[i] = coeffs\u000a\u000a    return filterMatrix\u000a        \u000a
p476
sg33
I01
sbsg34
g353
sbag0
(g45
g2
Ntp477
Rp478
(dp479
g49
V<p>Apply</p>
p480
sg34
g353
sbag0
(g23
g2
Ntp481
Rp482
(dp483
g27
g0
(g28
g2
Ntp484
Rp485
(dp486
g27
Vfrom larch.pres.html import Html\u000afrom larch.live import LiveValue, LiveFunction\u000afrom larch.controls import slider\u000a\u000a\u000alog_freq_scale_factor = LiveValue(0.0)\u000a\u000a@LiveFunction\u000adef freq_scale_factor():\u000a    return 4.0 ** log_freq_scale_factor.value\u000a\u000a\u000a@LiveFunction\u000adef modulated_audio():\u000a    filters = filter_bank(len(frames_freq[0]), freq_scale_factor.value)    \u000a    \u000a    filtered_freq = [np.dot(f, filters)   for f in frames_freq]\u000a    return audio_processing.wav_player_from_freq_windowed_frames(filtered_freq, sample_rate)\u000a\u000a\u000aHtml('<h1>Voice modulator</h1>',\u000a     'Frequency scale: ', freq_scale_factor, '<br>',\u000a     slider.live_slider(log_freq_scale_factor, min=-1.0, max=1.0, step=0.1, width=500),\u000a     '<br>',\u000a     modulated_audio)\u000a
p487
sg33
I01
sbsg34
g353
sbasbsg35
Vvoice_mod
p488
sg37
I3
sbasb.